{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tyj3RJn5NwBz",
        "outputId": "69421d84-a356-4238-a0ce-69e6f5ac389e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]   Package genesis is already up-to-date!\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Package nps_chat is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.corpus import sentiwordnet as swn\n",
        "from nltk.wsd import lesk\n",
        "from nltk.book import *\n",
        "import math\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('genesis')\n",
        "nltk.download('inaugural')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('treebank')\n",
        "nltk.download('webtext')\n",
        "\n",
        "nltk.download('sentiwordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet is a premade hierarchical organization of nouns, verbs, adjectives and adverbs. In Python, WordNet can be imported as a library and used to process text by making it easy to convert raw strings into their respective synsets, as well as find definitions, short examples of the word in context, and relations to other words in WordNet."
      ],
      "metadata": {
        "id": "LWaBzFUJyWUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output all synsets of light\n",
        "wn.synsets('light')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNfQBzh9yZ4M",
        "outputId": "d7e7585e-3808-4043-c0f8-fae848d146f1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('light.n.01'),\n",
              " Synset('light.n.02'),\n",
              " Synset('light.n.03'),\n",
              " Synset('luminosity.n.01'),\n",
              " Synset('light.n.05'),\n",
              " Synset('light.n.06'),\n",
              " Synset('light.n.07'),\n",
              " Synset('light.n.08'),\n",
              " Synset('light.n.09'),\n",
              " Synset('light.n.10'),\n",
              " Synset('sparkle.n.01'),\n",
              " Synset('light.n.12'),\n",
              " Synset('inner_light.n.01'),\n",
              " Synset('light.n.14'),\n",
              " Synset('lighter.n.02'),\n",
              " Synset('light.v.01'),\n",
              " Synset('light_up.v.05'),\n",
              " Synset('alight.v.01'),\n",
              " Synset('ignite.v.01'),\n",
              " Synset('fall.v.20'),\n",
              " Synset('unhorse.v.01'),\n",
              " Synset('light.a.01'),\n",
              " Synset('light.a.02'),\n",
              " Synset('light.a.03'),\n",
              " Synset('light.a.04'),\n",
              " Synset('light.a.05'),\n",
              " Synset('light.a.06'),\n",
              " Synset('unaccented.s.02'),\n",
              " Synset('light.s.08'),\n",
              " Synset('light.s.09'),\n",
              " Synset('clean.s.03'),\n",
              " Synset('light.s.11'),\n",
              " Synset('light.s.12'),\n",
              " Synset('light.a.13'),\n",
              " Synset('light.a.14'),\n",
              " Synset('faint.s.04'),\n",
              " Synset('light.s.16'),\n",
              " Synset('abstemious.s.02'),\n",
              " Synset('light.s.18'),\n",
              " Synset('light.s.19'),\n",
              " Synset('light.s.20'),\n",
              " Synset('idle.s.04'),\n",
              " Synset('light.s.22'),\n",
              " Synset('light.s.23'),\n",
              " Synset('light.s.24'),\n",
              " Synset('easy.s.10'),\n",
              " Synset('lightly.r.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select one synset of light and extract its definition, usage examples, and lemmas\n",
        "light = wn.synset('light.n.01')\n",
        "print(light.definition())\n",
        "print(light.examples())\n",
        "print(light.lemmas())\n",
        "\n",
        "# traverse up the WordNet hierarchy and output synsets\n",
        "hyper = lambda s: s.hypernyms()\n",
        "list(light.closure(hyper))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehiFPsz7zLsF",
        "outputId": "005d08bf-9fc1-4c86-8b33-3965df12304e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(physics) electromagnetic radiation that can produce a visual sensation\n",
            "['the light was filtered through a soft glass window']\n",
            "[Lemma('light.n.01.light'), Lemma('light.n.01.visible_light'), Lemma('light.n.01.visible_radiation')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('actinic_radiation.n.01'),\n",
              " Synset('electromagnetic_radiation.n.01'),\n",
              " Synset('radiation.n.01'),\n",
              " Synset('energy.n.01'),\n",
              " Synset('physical_phenomenon.n.01'),\n",
              " Synset('natural_phenomenon.n.01'),\n",
              " Synset('phenomenon.n.01'),\n",
              " Synset('process.n.06'),\n",
              " Synset('physical_entity.n.01'),\n",
              " Synset('entity.n.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet organizes nouns in a single, massive tree with a single root node, entity. Children of nodes in the tree are nouns in the category of their parent, i.e. 'radiation.n.01' is the child of 'energy.n.01'. Leaves of the tree are specific nouns, such as light. "
      ],
      "metadata": {
        "id": "WKdAYOCF1nvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output synset relations for a synset of light\n",
        "print('hypernyms: ', light.hypernyms())\n",
        "print('hyponyms: ', light.hyponyms())\n",
        "print('meronyms: ', light.part_meronyms())\n",
        "print('holonyms: ', light.part_holonyms())\n",
        "print('antonyms: ', light.lemmas()[0].antonyms())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPErES841v5A",
        "outputId": "9108d1e6-f5ee-48a8-f36b-6c15532ffa49"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hypernyms:  [Synset('actinic_radiation.n.01')]\n",
            "hyponyms:  [Synset('beam.n.04'), Synset('candlelight.n.01'), Synset('corona.n.04'), Synset('counterglow.n.01'), Synset('daylight.n.02'), Synset('firelight.n.01'), Synset('fluorescence.n.01'), Synset('friar's_lantern.n.01'), Synset('gaslight.n.01'), Synset('glow.n.05'), Synset('half-light.n.01'), Synset('incandescence.n.01'), Synset('lamplight.n.01'), Synset('luminescence.n.01'), Synset('meteor.n.02'), Synset('moonlight.n.01'), Synset('radiance.n.01'), Synset('scintillation.n.01'), Synset('starlight.n.01'), Synset('streamer.n.01'), Synset('sunlight.n.01'), Synset('torchlight.n.01'), Synset('twilight.n.02')]\n",
            "meronyms:  []\n",
            "holonyms:  [Synset('electromagnetic_spectrum.n.01')]\n",
            "antonyms:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output all synsets of explode\n",
        "wn.synsets('explode')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFPnugLP744c",
        "outputId": "d34cac15-9bcd-482e-8f7f-8e8307d57de9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('explode.v.01'),\n",
              " Synset('explode.v.02'),\n",
              " Synset('explode.v.03'),\n",
              " Synset('explode.v.04'),\n",
              " Synset('explode.v.05'),\n",
              " Synset('explode.v.06'),\n",
              " Synset('explode.v.07'),\n",
              " Synset('explode.v.08'),\n",
              " Synset('detonate.v.02'),\n",
              " Synset('explode.v.10')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select one synset of explode and extract its definition, usage examples, and lemmas\n",
        "explode = wn.synset('explode.v.01')\n",
        "print(explode.definition())\n",
        "print(explode.examples())\n",
        "print(explode.lemmas())\n",
        "\n",
        "# traverse up the WordNet hierarchy and output synsets\n",
        "hyper = lambda s: s.hypernyms()\n",
        "list(explode.closure(hyper))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TybJ82HK9fVX",
        "outputId": "3a009b93-9ae3-47b4-be47-53d851001bb1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cause to burst with a violent release of energy\n",
            "['We exploded the nuclear bomb']\n",
            "[Lemma('explode.v.01.explode'), Lemma('explode.v.01.detonate'), Lemma('explode.v.01.blow_up'), Lemma('explode.v.01.set_off')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('change_integrity.v.01'), Synset('change.v.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet organizes verbs similarly to nouns, but with a few key differences. Verbs do not have a top level synset, and are therefore organized into many smaller trees. Verbs also tend to be less well connected than nouns."
      ],
      "metadata": {
        "id": "OcVm46Y3AnX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use morphy to find different forms of the word\n",
        "print(wn.morphy('exploded'))\n",
        "print(wn.morphy('explodes'))\n",
        "print(wn.morphy('exploding'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM_m8v6sAz3n",
        "outputId": "c55e4ce6-2d85-4c3d-def0-b575fc5697a5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "explode\n",
            "explode\n",
            "explode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# select two similar words\n",
        "oven = wn.synset('oven.n.01')\n",
        "stove = wn.synset('stove.n.01')\n",
        "\n",
        "# run the Wu-Palmer similarity metric\n",
        "print(wn.wup_similarity(oven, stove))\n",
        "\n",
        "# run the Lesk algorithm\n",
        "sent = ['Dinner', 'is', 'in', 'the', 'oven']\n",
        "print(lesk(sent, 'oven'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYqFLHQpTAzT",
        "outputId": "4d97ec15-9954-4664-c2c7-3c8eb727a2e0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9166666666666666\n",
            "Synset('oven.n.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Wu-Palmer similarity metric correctly reported a high similarity between the nouns 'oven' and 'stove'. The Lesk algorithm correctly selected the 'oven.n.01' synset from the context 'Dinner is in the oven'."
      ],
      "metadata": {
        "id": "q1T_PCuxVSve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SentiWordNet is used to associate sentiments to words in natural language processing. SentiWordNet could be used in sentiment analsis in marketing analytics to judge the performance of a social media post by comparing the overall sentiment of comments to a baseline."
      ],
      "metadata": {
        "id": "6k1Ve8_lV4nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select an emotionally charged word and find its senti-synsets\n",
        "syn_list = list(swn.senti_synsets('lost'))\n",
        "\n",
        "# output the polarity score for each word\n",
        "for senti in syn_list:\n",
        "  print(senti)\n",
        "\n",
        "print(\"\")\n",
        "# make up a sentence\n",
        "sent = 'that kitten is adorable'\n",
        "\n",
        "# output the polarity for each word in the sentence\n",
        "tokens = sent.split()\n",
        "for token in tokens:\n",
        "  syn_list = list(swn.senti_synsets(token))\n",
        "  if syn_list:\n",
        "    print(syn_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viEdAC2bWNV0",
        "outputId": "b0427bcc-0fea-4aa7-981d-8ebed9bab8f4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<doomed.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<lose.v.01: PosScore=0.0 NegScore=0.5>\n",
            "<lose.v.02: PosScore=0.0 NegScore=0.5>\n",
            "<lose.v.03: PosScore=0.0 NegScore=0.5>\n",
            "<misplace.v.01: PosScore=0.0 NegScore=0.125>\n",
            "<lose.v.05: PosScore=0.0 NegScore=0.125>\n",
            "<lose.v.06: PosScore=0.0 NegScore=0.0>\n",
            "<lose.v.07: PosScore=0.0 NegScore=0.125>\n",
            "<lose.v.08: PosScore=0.0 NegScore=0.125>\n",
            "<fall_back.v.04: PosScore=0.0 NegScore=0.0>\n",
            "<miss.v.01: PosScore=0.0 NegScore=0.25>\n",
            "<suffer.v.11: PosScore=0.0 NegScore=0.25>\n",
            "<lost.a.01: PosScore=0.0 NegScore=0.75>\n",
            "<confused.s.03: PosScore=0.0 NegScore=0.0>\n",
            "<lost.a.03: PosScore=0.0 NegScore=0.625>\n",
            "<lost.a.04: PosScore=0.0 NegScore=0.625>\n",
            "<lost.s.05: PosScore=0.0 NegScore=0.5>\n",
            "<lost.s.06: PosScore=0.125 NegScore=0.625>\n",
            "<bemused.s.01: PosScore=0.125 NegScore=0.0>\n",
            "<baffled.s.01: PosScore=0.0 NegScore=0.5>\n",
            "<helpless.s.02: PosScore=0.0 NegScore=0.875>\n",
            "\n",
            "<kitten.n.01: PosScore=0.0 NegScore=0.0>\n",
            "<be.v.01: PosScore=0.25 NegScore=0.125>\n",
            "<adorable.s.01: PosScore=0.5 NegScore=0.0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SentiWordNet reported plausible polarities for the synset of 'lost'. Additionally, SentiWordNet reported overall positive polarity for the sentence 'That kitten is adorable', which is expected. Sentiment analysis is useful in NLP applications in marketing and human computer interfaces. Alexa/Google devices may be able to simplify complex responses into simple yes/no answers based on sentiment analysis."
      ],
      "metadata": {
        "id": "EyoTZ2b_Zw2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collocations are occurances of two or more words that combine to form a meaning in a somewhat unique way. Key to this concept is that individual words in collocations cannot be replaced with synonyms to achieve the same meaning. For example, 'strong' in 'strong tea' cannot be replaced with 'muscular'."
      ],
      "metadata": {
        "id": "0EDGbatycCsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output collocations for text4\n",
        "print(text4.collocations())\n",
        "\n",
        "# calculate mutual information\n",
        "vocab = len(set(text4))\n",
        "text = ' '.join(text4.tokens)\n",
        "old_world = text.count('Old World') / vocab\n",
        "old = text.count('Old') / vocab\n",
        "world = text.count('World') / vocab\n",
        "math.log2(old_world / (old * world))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPbS4zbndaQf",
        "outputId": "71b122b7-d841-431f-e190-2362f400c293"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n",
            "None\n",
            "0.000997506234413965\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.983886091037398"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result of the mutual information formula for 'Old World' is 8.98. Since it is positive, there is likely a collocation."
      ],
      "metadata": {
        "id": "_h9HQ0skgNbv"
      }
    }
  ]
}